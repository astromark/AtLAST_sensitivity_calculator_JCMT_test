{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "354481f6",
   "metadata": {
    "tags": []
   },
   "source": [
    "# AtLAST Telescope Simulator - Line Emission \n",
    "\n",
    "One of the key first light instruments for AtLAST will be some kind of high spectral resolution camera, operating at at least one waveband at a time.  This Jupyter notebook creates a simplistic simulation of what we can expect the performance of that telescope/instrument combination to be using the AtLAST Sensitivity Calculator as its starting point.\n",
    "\n",
    "This notebook is provided as an example of how to setup a telescope simulation for AtLAST using the Sensitivity Calculator.  You can either modify it to suit your own use case / input file, or create your own using this as a guide.  \n",
    "\n",
    "## What this Simulator *can* do:\n",
    "* Take observing constraints in the same way the sensitivity calculator does\n",
    "* Import a user suplied FITS file to simulate observing\n",
    "* Convolve the FITS file to the resolution expected at the requested observing frequency\n",
    "* Add a constant gaussian noise level to the image consistent with what AtLAST would expect to obtain (either as specified, or given the amount of integration time requested)\n",
    "\n",
    "\n",
    "## What this Simulator *can't* do:\n",
    "* Simulate any spacings between individual detectors/pixels (out of scope with no instrument specification)\n",
    "* Simulate fall off in sensitivity as a function of distance from pointing centre / chopping constraints (out of scope with no detailed calibration strategy analysis)\n",
    "\n",
    "\n",
    "## Stepping through this example Notebook\n",
    "\n",
    "This example notebook is provided as a reference/guide on how to setup an AtLAST simulation given an input FITS file.  The steps below include:\n",
    "\n",
    "1. Setup the simulator (importing libraries, setting up plotting routines, etc)\n",
    "2. Input the user specified quantities (time/sensitivity request, observing parameters, input FITS file, etc)\n",
    "3. Convolve the input file to the (spatial and spectral) resolution expected for an AtLAST observation at the given input frequency\n",
    "4. Compare the input image to the expected instrument footprint (using number of pixels)\n",
    "4. Determine the noise level to apply to the data\n",
    "5. Apply a gaussian noise level to the data\n",
    "6. Show a collapsed image and an averaged spectrum\n",
    "7. Inform the user how many instrument footprints are required to image their FoV.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f45984d2-7efd-448d-88d0-a8c3fb1f87ec",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "# Setup The Simulator\n",
    "\n",
    "Below we import all of the relevant python packages for the sensitivity calculation and telescope simulation, including setting up for importing and displaying FITS images\n",
    "\n",
    "There are also cells which setup functions for use later in the notebook.\n",
    "\n",
    "## Import the AtLAST Sensitivity Calculator package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c94b6b10-e0b9-417d-8fa5-e46ed9445995",
   "metadata": {},
   "outputs": [],
   "source": [
    "from atlast_sc.calculator import Calculator"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e04096a-3e0b-4c48-85c0-60b9b7edb77b",
   "metadata": {},
   "source": [
    "## Import astronomy specific packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95f55cd8-7349-4ec9-8024-aa8a0655cecf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# to use astropy coordinates and units\n",
    "import astropy.units as u  # for ensuring units are treated properly\n",
    "import astropy.constants as const # to make use of the astropy constants package\n",
    "\n",
    "# to handle FITS files\n",
    "from astropy.io import fits # to import and manipulate FITS files\n",
    "from astropy.wcs import WCS # to use WCS information from the FITS headers\n",
    "\n",
    "# to reproject the convolved image onto a new grid\n",
    "from reproject import reproject_interp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3135d5b7-6b9b-431d-8f59-1e50c3f3b7a3",
   "metadata": {},
   "source": [
    "## Visualisation Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c78b6873-2db7-4ce9-8729-75b3e6d4dd31",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import Matplotlibs pyplot package\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Import the Rectangle patch to draw the FoV on the final image\n",
    "from matplotlib.patches import Rectangle\n",
    "\n",
    "# show the plots inline\n",
    "%matplotlib inline\n",
    "\n",
    "# to allow for wide figures as required\n",
    "plt.rcParams['figure.figsize'] = [18, 8]\n",
    "\n",
    "# suppress the warnings output by astropy when headers are accessed\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28a93dc4-f785-4ef2-bb15-119fb424d83a",
   "metadata": {},
   "source": [
    "## Imports for Gaussian noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d39f5b5c-2af7-4621-9c97-8b24b8afe414",
   "metadata": {},
   "outputs": [],
   "source": [
    "# gaussian noise imports\n",
    "import numpy as np\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c639cd25-e020-4527-a33f-b8061d3403ff",
   "metadata": {},
   "source": [
    "## User defined functions used in the rest of this notebook\n",
    "\n",
    "Here we define all of the functions to be used later. This includes a downsampling algorithm which calculates what the refactored header should have as its keywords, and a function which converts between velocity and frequency (at a given frequency) to help with bandwidth calculations.  Note that the conversion being done here is different from the `astropy` equivalencies package which converts the difference between input value and rest frequency into the equivalent units, rather than expecting a bandwidth to be converted. The equation used here is:\n",
    "\n",
    "$$ \\frac{\\Delta \\nu}{\\nu} = \\frac{\\Delta v}{c}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60764214-d6f7-4a55-9dd9-addf2367cb09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# downsampling function that changes the relevant keywords in the user provided header by scaling them down by a factor of `factor`\n",
    "\n",
    "def downsample(header,calculator,sampling):\n",
    "    inhead = header\n",
    "    modhead = header.copy()\n",
    "    \n",
    "    # get current resolution, and derive scaling to reqired\n",
    "    dish_diam = 2* calculator.instrument_setup.dish_radius.value\n",
    "    \n",
    "    # calculate spatial CDELT value for new header\n",
    "    spat_cd = (1.2 * (const.c / calculator.obs_freq) / dish_diam )/sampling\n",
    "    spat_fact = (inhead['CDELT1']/spat_cd.decompose()).value # ratio between old and new spatial resolution\n",
    "    \n",
    "    # calculate spectral CDELT value for new header\n",
    "    spec_cd = calculator.bandwidth.to('Hz').value\n",
    "    spec_fact = inhead['CDELT3']/spec_cd\n",
    "\n",
    "    # loop over CDELT and scaling factors to set header variables\n",
    "    scale = np.abs([spat_fact,spat_fact,spec_fact])\n",
    "    print(scale)\n",
    "    \n",
    "    for i in [1,2,3]:  #(x,y,z) scaling\n",
    "        modhead[f'CDELT{i}'] = inhead[f'CDELT{i}']*scale[i-1]\n",
    "        modhead[f'CRPIX{i}'] = inhead[f'CRPIX{i}']/scale[i-1]\n",
    "        modhead[f'NAXIS{i}'] = int(inhead[f'NAXIS{i}']/scale[i-1])\n",
    "    \n",
    "    \n",
    "    \n",
    "        \n",
    "    return modhead\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "# convert between velocity and frequency for bandwidth calculations\n",
    "def equiv(obs_freq, in_bandwidth):\n",
    "    if in_bandwidth.unit.is_equivalent(u.km/u.s):  # calculate bandwidth in frequency\n",
    "        output = (in_bandwidth * obs_freq / const.c).to(u.MHz)\n",
    "    elif in_bandwidth.unit.is_equivalent(u.Hz):  # calculate bandwidth in velocity\n",
    "        output = (in_bandwidth * const.c / obs_freq).to(u.km/u.s)\n",
    "    else:\n",
    "        print('units not consistent with velocity or frequency, returning original')\n",
    "        output = in_bandwidth\n",
    "    return output\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "634d1bc4-6f9c-4b8e-8f06-e279d929c1c5",
   "metadata": {},
   "source": [
    "# Input User Specified Quantities\n",
    "\n",
    "Here we generate an instance of the sensitivity calculator which we use for the rest of this simulation notebook.  The first part of this section shows you what the default settings are for the calculator to:\n",
    "1) Show what the default settings are\n",
    "2) Show the naming convention for the user editable parameters\n",
    "\n",
    "We then go through changing some of those parameters and displaying how that changed the variables used for the sensitivity or integration time calculation, followed  by setting the number of pixels to be simulated in this notebook, and the input FITS image to be used in the simulation.  The simulator assumes a fully sampled array of pixels arranged in a square because we don't know the exact properties of any of the instruments expected for AtLAST.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a67e19f4-5a1e-4f5a-9710-e7d9397f153a",
   "metadata": {},
   "source": [
    "## Initialise calculator and see default parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46c388ed-1aaf-482a-a918-b4f83465bd81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create an instance of the calculator\n",
    "calculator = Calculator()\n",
    "#show the default values used in the calculation\n",
    "print(calculator.user_input)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a60b96f8-d95d-4fbd-8df2-70bde8da2f24",
   "metadata": {},
   "source": [
    "Listed above are the parameters most commonly edited in the sensitivity calculator. Note that both integration time and sensitivity are listed here, while the calculator only uses one of them at a time to derive the other.  In addition to `calculator.user_input`, there are two other files that could be output here:\n",
    "\n",
    "`calculator.instrument_setup`: Gives a number of changable parmeters such as the telescope diameter - for those looking to see the effects of having a smaller diameter\n",
    "\n",
    "`calculator.derived_parameters`: Using the input parameters, there are a number of parameters the simulator derives. Users can inspect those values by printing this out.\n",
    "\n",
    "\n",
    "## Change some of the input parameters\n",
    "\n",
    "Now that we know what the variable names are for the input parameters, we can change some of them to reflect the simulated observation we want to make. Specifically lets change the spectral resolution to be the equivalent of 1 km/s. For this, we need to use the `astropy` equivalencies package."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35fb7228-f6f3-420b-af54-31f30da08230",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set an integration time\n",
    "calculator.t_int = 3000 *u.s\n",
    "\n",
    "# change the observing frequency to see how the user input changes\n",
    "calculator.obs_freq = 345.*u.GHz\n",
    "\n",
    "# change the observing bandwidth by specifying a velocity resolution (in km/s)\n",
    "velo = 1 *u.km/u.s\n",
    "bandwidth = equiv(calculator.obs_freq,velo)  # use the function above to convert to frequency\n",
    "calculator.bandwidth = bandwidth\n",
    "\n",
    "# print out the input parameters to show that they've changed\n",
    "print(calculator.user_input)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cefa7eb-3afd-4f12-add8-c2596eb322db",
   "metadata": {},
   "source": [
    "## Specify the image to be used in the simulation\n",
    "\n",
    "Ideally, here you would specify an oversampled base image to which the simulator can attach a gaussian noise level derived from the sensitivity calculator. In this example, we use an ALMA archive spectral cube of the Orion Bar because it is chemically rich, and at better (spatial) resolution than we expect to get with AtLAST. The input FITS file can be downloaded from the ALMA archive, and is not included in this directory.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6b8c69c-7422-4c16-a814-eb901d5f4d73",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import an example image\n",
    "filename = 'member.uid___A002_X6dddc4_X6a.Orion_Bar.COnocont.Clean.image.fits'  \n",
    "hdu = fits.open(filename)[0]\n",
    "wcs = WCS(hdu.header)\n",
    "\n",
    "#ALMA and reproject use different cases for UTC (uppercase vs. lowercase)\n",
    "# convert the ALMA header to meet the reproject requirement\n",
    "hdu.header['TIMESYS'] = 'utc'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c98575fc-85bb-4952-974c-1332c9b42c0f",
   "metadata": {},
   "source": [
    "## Set the number of pixels to be simulated\n",
    "\n",
    "Here we setup the number of pixels expected for the instrument. For a spectral line reciever, we hope to achieve of order 1000 pixels, while for a continuum camera, we expect much closer to $10^6$.  Because this is a line example, we'll use 1000 as the number of pixels here.\n",
    "\n",
    "As noted above, we cannot take pixel spacing into account because we don't have specifications for our cameras. As such, this simulator simply places a square box containing as close to the input number of pixels as possible (scaling up slightly to provide an integer number of pixels in either spatial direction)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b37eaeb4-d5c5-42b9-a836-9d6dfb0a6a66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# simulator/imaging settings\n",
    "Npix_detector = 1000\n",
    "len_detector = math.ceil(np.sqrt(Npix_detector))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f387ce6a-27a3-48aa-989b-eef50a8da352",
   "metadata": {},
   "source": [
    "## Calculate pixel scale / beam size based on observing frequency and telescope diameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bb24ada-513a-4905-b72e-14e9b1f27358",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pull the telescope radius from the instrument_setup\n",
    "radius = calculator.instrument_setup.dish_radius.value\n",
    "# pull the observing frequency from the user inputs\n",
    "freq = calculator.user_input.obs_freq.value\n",
    "\n",
    "theta = ((1.2* const.c / (freq * (2*radius) ))*u.radian).to('arcsec')\n",
    "print(f'Given the requested observing frequency, the resolution of AtLAST will be {theta:0.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a05421f-321a-4ab6-9938-9f2c610e6cac",
   "metadata": {},
   "source": [
    "## Set the pixel sampling of the convolved image\n",
    "\n",
    "When the image is convolved to the resolution of AtLAST, we need to downsample the pixel scaling accordingly. Usual rule of thumb is 3-5 pixels per resolution element. That sampling is set here for use in section 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8b3d326-b26f-4b6c-b03c-2fd14bd7ab01",
   "metadata": {},
   "outputs": [],
   "source": [
    "sampling = 5  # provide 5 pixels for each resolution element of the instrument"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3714c511-503a-45c4-87ac-5eb912d39a71",
   "metadata": {},
   "source": [
    "# Display the input data and convolve it to the resolution of AtLAST\n",
    "\n",
    "Now that we have input data, and the sensitivity calculator setup, we can begin the process of simulating an observation with AtLAST.  The first step in that process is to convolve the input data to the resolution expected for AtLAST.  Below we:\n",
    "\n",
    "* Show an averaged (collapsed) image cube at its original spatial resolution and a spectrum averaged over the imaged area\n",
    "* Derive the smoothing kernel required to convolve that data to the spatial and spectral resolution of AtLAST \n",
    "* Resample the input data to the AtLAST resolution\n",
    "* Show a small area of the input image at original and convolved resolution to show what happened\n",
    "* Compare the size of the input image to the expected instrument footprint (instrument field of view)\n",
    "\n",
    "\n",
    "## Show the original data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ddafb97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the data from the input FITS file\n",
    "data = hdu.data\n",
    "# give data units from header (need capitalize in order to give Jy instead of JY, which astropy.units complains about)\n",
    "data=  data*u.Unit(hdu.header['bunit'].capitalize()) \n",
    "\n",
    "# set the data plotting limits by finding the min/max values over most of the image (removing edges), and scaling the max to 10% of max to avoid spikes and saturated pixels\n",
    "vmin,vmax = np.nanmin(data[0,:,10:-10,10:-10]).value,np.nanmax(data[0,:,10:-10,10:-10]).value\n",
    "noise = np.nanstd(data)\n",
    "\n",
    "### show collapsed image\n",
    "\n",
    "#collapse over the (degenerate) stokes and spectral axes\n",
    "img_collapse = np.nanmean(data,axis=(0,1))\n",
    "\n",
    "# show the input data\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(projection=wcs.celestial)  # add the WCS information to the plot\n",
    "im = ax.imshow(img_collapse.value,origin='lower',cmap='twilight_r')\n",
    "# add a colorbar\n",
    "cbar = plt.colorbar(im)\n",
    "cbar.set_label(data.unit)\n",
    "\n",
    "### show collapsed spectrum\n",
    "\n",
    "# collapse over the (degenerate) stokes and spatial axes\n",
    "spec_collapse = np.nanmean(data,axis=(0,2,3))\n",
    "# get values of spectral axis from the header\n",
    "spec_axis = wcs.spectral.array_index_to_world_values(list(range(0,len(spec_collapse))))\n",
    "\n",
    "# show the input data\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot()\n",
    "spec = ax.plot(spec_axis,spec_collapse)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba1a6456-0817-4e59-98b0-44cdd87524aa",
   "metadata": {},
   "source": [
    "## Resample the data to the (requested) resolution of AtLAST\n",
    "\n",
    "Use the header information of the original image to find its pixel scale, and calculate the resampling factors required to create an AtLAST observation at the user specified spectral resolution and spatial resolution set by the telescope diameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "658f5dea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convolve the image to the beamsize at the requested observing frequency\n",
    "#pix_scale = (hdu.header['cdelt1']*u.deg).to('arcsec')\n",
    "#kern = (theta/pix_scale).value\n",
    "#kernel = Gaussian2DKernel(x_stddev=kern)\n",
    "\n",
    "# convolve the data with the gaussian kernel, and save the results for the reprojection below.\n",
    "#astropy_conv = convolve(data,kernel)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1685c31a-9050-44d5-bdb1-ac09d7674afd",
   "metadata": {},
   "source": [
    "## Downsample to the AtLAST pixel scale\n",
    "\n",
    "Convolving the input image above doesn't change the size of the pixels in the original image, only smooths it.  Here we use the `reproject` package to do that downsampling on the data, and use the downsamplig function to update the header keywords accordingly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "638ed8f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a downsampled header using the 'downsample' function and sampling set in sections 2.5 and 3.6 (respectively)\n",
    "ds_header = downsample(hdu.header,calculator,sampling)\n",
    "\n",
    "# reproject the convolved image to the downsampled header\n",
    "array,footprint = reproject_interp((hdu.data,hdu.header),ds_header)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d68e62bb-e916-49ca-9562-2ef314afac81",
   "metadata": {},
   "source": [
    "## Resample to AtLAST resolution\n",
    "\n",
    "Plot the original and the convolved/regridded data to show how the convolution has changed how the data look. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb02dbf7-52a5-4e74-a2ef-b4991215087c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the resampled data and give units from header \n",
    "newdata=  array*u.Unit(hdu.header['bunit'].capitalize()) \n",
    "# load in the new wcs information\n",
    "newwcs = WCS(ds_header)\n",
    "\n",
    "### show collapsed images\n",
    "# iterate over the original and resampled images\n",
    "indata = [data,newdata]\n",
    "inwcs = [wcs,newwcs]\n",
    "labels = ['Original','Resampled']\n",
    "\n",
    "fig = plt.figure()\n",
    "for i in (0,1):\n",
    "\n",
    "    #collapse over the (degenerate) stokes and spectral axes in the resampled data\n",
    "    img_collapse = np.nanmean(indata[i],axis=(0,1))\n",
    "\n",
    "    # show the resampled data\n",
    "    ax = fig.add_subplot(1,2,i+1,projection=inwcs[i].celestial)  # add the WCS information to the plot\n",
    "    im = ax.imshow(img_collapse.value,origin='lower',cmap='twilight_r')\n",
    "    ax.set_title(labels[i])\n",
    "    # add a colorbar\n",
    "    cbar = plt.colorbar(im)\n",
    "    cbar.set_label(data.unit)\n",
    "\n",
    "\n",
    "### show collapsed spectra\n",
    "# iterate over the original and resampled spectra\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot()\n",
    "\n",
    "for i in (0,1):\n",
    "    # collapse over the (degenerate) stokes and spatial axes\n",
    "    spec_collapse = np.nanmean(indata[i],axis=(0,2,3))\n",
    "    # get values of spectral axis from the header\n",
    "    spec_axis = inwcs[i].spectral.array_index_to_world_values(list(range(0,len(spec_collapse))))\n",
    "    # show the spectrum and give it a label\n",
    "    spec = ax.plot(spec_axis,spec_collapse,label=labels[i])\n",
    "\n",
    "    # show the legend on the plot\n",
    "ax.legend()\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efb10881",
   "metadata": {},
   "source": [
    "# Evaluate image size compared to observing footprint\n",
    "\n",
    "As the number of pixels in a detector varies, so does the amount of the telescope field of view it can capture in a single setup. Here we look at whether the input image is large enough to fill the instrument footprint \n",
    "\n",
    "**Image smaller than footprint**\n",
    "\n",
    "If the image is not big enough to fill the instrument footprint, then the image will be padded out with zeros to show how large the instrument footprint would be in comparison to the input image. In this case the convolved input image is centred in the new, zero padded, array, and the header is updated accordingly. Here, the instrument footprint is also plotted on the image.\n",
    "\n",
    "**Image larger than footprint**\n",
    "\n",
    "If the image is larger than the instrument footprint, then the code below draws a red box in the centre of the image to indicate the footprint, and also outputs how many observations (and therefore on-source integration time) are required to observe the entire image, rounding up the number of footprints to an integer value.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04db33b3-d69b-4fb4-8c8b-a0d83a78fb93",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "array.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c90e97b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the shape of the input (convolved) image\n",
    "s1,z1,y1,x1 = array.shape  #badkwards here to make the rest make sense (see note above about python vs. FITS handling of first axis)\n",
    "\n",
    "# find which is larger, the x or y coordinate, or the number of detector pixels across that dimension\n",
    "pad = np.max((x1,len_detector)),np.max((y1,len_detector))\n",
    "\n",
    "\n",
    "header = ds_header.copy()  #create a new copy of the header information\n",
    "\n",
    "# determine if the image is smaller than the instrument footprint in either x or y\n",
    "\n",
    "# yes, one or more dimensions are smaller\n",
    "if x1 <= len_detector or y1 <= len_detector:\n",
    "    for i in (0,1):\n",
    "\n",
    "        cp = 'CRPIX{0:d}'.format(i+1)\n",
    "        na = 'NAXIS{0:d}'.format(i+1)\n",
    "        header[cp] = int(math.ceil(pad[i]/2))\n",
    "        header[na] = int(pad[i])\n",
    "\n",
    "    # find the padding required to create that array & add zeros to the data\n",
    "    pads = [int((len_detector-x1)/2),int((len_detector-y1)/2)]\n",
    "    pads.insert(1,pads[0])\n",
    "    pads.insert(-1,pads[-1])\n",
    "    pads = [0 if i < 0 else i for i in pads]\n",
    "    \n",
    "    # create the padded data array using the numpy 'pad' module\n",
    "    array = np.pad(array,((pads[2:]),(pads[:2])),'constant',constant_values=0)\n",
    "\n",
    "# no, the image is larger than the instrument footprint    \n",
    "else:\n",
    "    # because the image is larger than the footprint, just pass the original array along for plotting\n",
    "    array = array    \n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(projection=WCS(header).celestial)\n",
    "img_collapse = np.nanmean(array,axis=(0,1))\n",
    "ax.imshow(img_collapse,origin='lower',cmap='twilight_r')\n",
    "\n",
    "# plot the detector footprint on the image (regardless of whether the image needed padding.\n",
    "#find where the first (bottom left) pixel of the rectangle should be\n",
    "startx = np.max((int(x1/2 - len_detector/2),0))\n",
    "starty = np.max((int(y1/2 - len_detector/2),0))\n",
    "\n",
    "# use the Rectangle patch to specify a box starting at (startx,starty) with dimensions of len_detector x len_detector\n",
    "rect = Rectangle((startx,starty),len_detector,len_detector,edgecolor='r',facecolor='None',lw=5)\n",
    "ax.add_patch(rect)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60fbd3f7-2805-4d00-9b4f-22c8343a7e01",
   "metadata": {},
   "source": [
    "# Determine the noise level to add to the image\n",
    "\n",
    "With the input image sufficiently processed, and the size of the instrument footprint compared to the image size, we can now setup use the sensitivity calculator to derive an integration time or sensitivity limit.\n",
    "\n",
    "In the example below, we use an integration time to derive a sensitivity limit, and then apply that noise level to the image.\n",
    "\n",
    "## Calculate sensitivity based on integration time\n",
    "\n",
    "Using the integration time set in section 3.2, we can calculate the single pixel sensitivity using the sensitivity calculator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af440dcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# copy the integration time from section 3.2\n",
    "integration_time = calculator.t_int\n",
    "\n",
    "# use telescope size to convert point source sensitivity to flux density \n",
    "# (assuming no beam dilution)\n",
    "calculated_sensitivity = calculator.calculate_sensitivity(integration_time).to(u.mJy)/theta**2\n",
    "print(\"Sensitivity: {:0.5f} for an integration time of {:0.2f} \".format(calculated_sensitivity, integration_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1800db7b-9531-48f7-bf3f-242034c25c46",
   "metadata": {},
   "source": [
    "## Add Gaussian noise to the image based on serived sensitivity calculation.\n",
    "\n",
    "Using the sensitivity above, create a noise map using the numpy gaussian (random normal) distribution module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da02a4b4-eb28-463b-9f2d-c64ecd1ae14f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sigma of the distribution comes from the sensitivity calculator\n",
    "sigma = calculated_sensitivity.to('mJy/arcsec2').value\n",
    "mean = 0 # trust that the continuum was subtracted properly\n",
    "\n",
    "gaussian_noise = np.random.normal(mean, sigma, (array.shape))*u.MJy/u.sr\n",
    "\n",
    "# add the noise to the image\n",
    "noisy_image = array+gaussian_noise.value"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b84f1e19-8787-405e-9fda-823954af7b48",
   "metadata": {},
   "source": [
    "# Plot the final results\n",
    "\n",
    "Now, with the gaussian noise level applied to the convolved and resampled image, we have the final simulated AtLAST observation to plot.  \n",
    "\n",
    "Below we plot 4 images, representative of the different steps followed through in this notebook:\n",
    "\n",
    "* the original data\n",
    "* the data convolved to the resolution of AtLAST\n",
    "* the Gaussian noise map applied to the image\n",
    "* the final image\n",
    "\n",
    "For the final 3, a single instrument footprint has been added to the image, as above in section 5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4463b9e1-0d5d-4fdd-86f4-ff0131091c58",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = [data.value,array,gaussian_noise.value,noisy_image]\n",
    "inwcs = [wcs,newwcs,newwcs,newwcs]\n",
    "titles = ['Input Data', 'Convolved to AtLAST Resolution',\n",
    "          'Noise Level of Observation', 'Observed Image']\n",
    "\n",
    "# calculate vmin/vmax for all images (from resampled input data)\n",
    "vmin,vmax = np.nanmin(np.nanmean(array,axis=(0,1))),np.nanmax(np.nanmean(array,axis=(0,1)))\n",
    "fig = plt.figure()\n",
    "for i in range(0,len(inputs)):\n",
    "\n",
    "    ax = fig.add_subplot(2,2,i+1, projection=wcs.celestial)\n",
    "    img_collapse = np.nanmean(inputs[i],axis=(0,1))\n",
    "    im=ax.imshow(img_collapse,vmin=vmin,vmax=vmax,origin='lower',cmap='twilight_r')\n",
    "    if i > 0:  # don't plot the instrument footprint on the original image (the way its pixels are counted is different)\n",
    "        rect = Rectangle((startx,starty),len_detector,len_detector,edgecolor='r',facecolor='None',lw=5)\n",
    "        ax.add_patch(rect)\n",
    "    ax.set_title(titles[i])\n",
    "    cbar = plt.colorbar(im)\n",
    "    cbar.set_label(data.unit)\n",
    "plt.tight_layout()   \n",
    "    \n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot()\n",
    "for i in range(0,len(inputs)):\n",
    "    # collapse over the (degenerate) stokes and spatial axes\n",
    "    spec_collapse = np.nanmean(inputs[i],axis=(0,2,3))\n",
    "    # get values of spectral axis from the header\n",
    "    spec_axis = inwcs[i].spectral.array_index_to_world_values(list(range(0,len(spec_collapse))))\n",
    "    # show the spectrum and give it a label\n",
    "    spec = ax.plot(spec_axis,spec_collapse,label=titles[i])\n",
    "\n",
    "    # show the legend on the plot\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f9624cf-7e22-4f65-b39b-3acbdd33f440",
   "metadata": {},
   "source": [
    "## Mapping Constraints\n",
    "\n",
    "Here, we evaluate whether mapping is required, and if so, the (integer) number of instrument footprints required to cover the input image.  The integration times reported here are a lower limit, and do not include any of the following:\n",
    "\n",
    "* array configurations that aren't fully sampled\n",
    "* array configurations that aren't square\n",
    "* off source (calibration time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08ebda7e-9d54-4b46-a8e2-0e8e26fd45e5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#find how many pointings of an N pixel detector would be required to observe the full image\n",
    "\n",
    "# number of pixels in the final image\n",
    "s,z,a,b = noisy_image.shape\n",
    "Npix_img = a*b\n",
    "N_int_actual = Npix_img/Npix_detector\n",
    "# find the whole number of footprints required to map the whole image\n",
    "N_int_ceiling = math.ceil(N_int_actual)\n",
    "\n",
    "# based on the number of footprints required, create the appropriate text to append to the overall output print statement.\n",
    "if N_int_ceiling > 1:\n",
    "    footprint = f'To fully image your map will require {N_int_ceiling} integrations, and a total on source time of {integration_time*N_int_ceiling}'\n",
    "\n",
    "elif N_int_ceiling<= 1:\n",
    "    footprint = f'The total on source integration time is {integration_time} (assuming the detector is fully sampled).'\n",
    "\n",
    "# tell the user how long their observation will take\n",
    "print(f'There are {Npix_img} pixels in the image, and {Npix_detector} on the detector, \\\n",
    "so {N_int_actual} integrations are required.  {footprint}')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
